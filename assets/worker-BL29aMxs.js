import{d as H,A as x,b as D,c as K,f as V,g as W,h as E,i as J,j as Y,a as P,k as tt,l as et,m as st,n as ot,o as nt,p as it,q as at,r as rt,s as lt,t as ct,u as pt,v as ut,w as dt,x as mt,y as M,z as R,B as C,C as ft,D as ht,E as U,F as _t,R as F,T as B,G as gt,H as yt,e as q}from"./image-O15s_1zf.js";import{A as b,r as wt}from"./processors-De2tF4GJ.js";import{T as kt}from"./config-YF015oXS.js";async function I(l){return Array.isArray(l)||(l=[l]),await Promise.all(l.map(t=>F.read(t)))}async function S(l,t){return Array.isArray(l)||(l=[l]),await Promise.all(l.map(e=>typeof e=="string"||e instanceof URL?wt(e,t):e instanceof Float64Array?new Float32Array(e):e))}function N(l,t){t&&(l=l.map(o=>o|0));const[e,s,a,i]=l;return{xmin:e,ymin:s,xmax:a,ymax:i}}class y extends yt{constructor({task:t,model:e,tokenizer:s=null,processor:a=null}){super(),this.task=t,this.model=e,this.tokenizer=s,this.processor=a}async dispose(){await this.model.dispose()}}class xt extends y{constructor(t){super(t)}async _call(t,{topk:e=1}={}){const s=this.tokenizer(t,{padding:!0,truncation:!0}),a=await this.model(s),i=this.model.config.problem_type==="multi_label_classification"?c=>c.sigmoid().data:c=>M(c.data),o=this.model.config.id2label,n=[];for(const c of a.logits){const u=i(c),m=R(u,e).map(d=>({label:o[d[0]],score:d[1]}));e===1?n.push(...m):n.push(m)}return Array.isArray(t)||e===1?n:n[0]}}class At extends y{constructor(t){super(t)}async _call(t,{ignore_labels:e=["O"]}={}){const s=Array.isArray(t),a=this.tokenizer(s?t:[t],{padding:!0,truncation:!0}),o=(await this.model(a)).logits,n=this.model.config.id2label,c=[];for(let u=0;u<o.dims[0];++u){const p=a.input_ids[u],m=o[u],d=[];for(let r=0;r<m.dims[0];++r){const f=m[r],h=C(f.data)[1],g=n?n[h]:`LABEL_${h}`;if(e.includes(g))continue;const _=this.tokenizer.decode([p[r].item()],{skip_special_tokens:!0});if(_==="")continue;const w=M(f.data);d.push({entity:g,score:w[h],index:r,word:_,start:null,end:null})}c.push(d)}return s?c:c[0]}}class bt extends y{constructor(t){super(t)}async _call(t,e,{topk:s=1}={}){const a=this.tokenizer(t,{text_pair:e,padding:!0,truncation:!0}),i=await this.model(a),o=[];for(let n=0;n<i.start_logits.dims[0];++n){const c=a.input_ids[n],u=c.indexOf(this.tokenizer.sep_token_id),p=Array.from(M(i.start_logits[n].data)).map((r,f)=>[r,f]).filter(r=>r[1]>u),m=Array.from(M(i.end_logits[n].data)).map((r,f)=>[r,f]).filter(r=>r[1]>u),d=ft(p,m).filter(r=>r[0][1]<=r[1][1]).map(r=>[r[0][1],r[1][1],r[0][0]*r[1][0]]).sort((r,f)=>f[2]-r[2]);for(let r=0;r<Math.min(d.length,s);++r){const[f,h,g]=d[r],_=[...c].slice(f,h+1),w=this.tokenizer.decode(_,{skip_special_tokens:!0});o.push({answer:w,score:g})}}return s===1?o[0]:o}}class vt extends y{constructor(t){super(t)}async _call(t,{topk:e=5}={}){const s=this.tokenizer(t,{padding:!0,truncation:!0}),a=await this.model(s),i=[];for(let o=0;o<s.input_ids.dims[0];++o){const n=s.input_ids[o],c=n.indexOf(this.tokenizer.mask_token_id);if(c===-1)throw Error(`Mask token (${this.tokenizer.mask_token}) not found in text.`);const p=a.logits[o][c],m=R(M(p.data),e);i.push(m.map(d=>{const r=[...n];return r[c]=d[0],{score:d[1],token:d[0],token_str:this.tokenizer.model.vocab[d[0]],sequence:this.tokenizer.decode(r,{skip_special_tokens:!0})}}))}return Array.isArray(t)?i:i[0]}}class X extends y{_key="generated_text";constructor(t){super(t)}async _call(t,e={}){Array.isArray(t)||(t=[t]),this.model.config.prefix&&(t=t.map(c=>this.model.config.prefix+c));const s=this.model.config.task_specific_params;s&&s[this.task]&&s[this.task].prefix&&(t=t.map(c=>s[this.task].prefix+c));const a=this.tokenizer,i={padding:!0,truncation:!0};let o;this instanceof G&&"_build_translation_inputs"in a?o=a._build_translation_inputs(t,i,e).input_ids:o=a(t,i).input_ids;const n=await this.model.generate(o,e);return a.batch_decode(n,{skip_special_tokens:!0}).map(c=>({[this._key]:c}))}}class zt extends X{_key="summary_text";constructor(t){super(t)}}class G extends X{_key="translation_text";constructor(t){super(t)}}class Mt extends y{constructor(t){super(t)}async _call(t,e={}){const s=Array.isArray(t);s||(t=[t]);const a=e.add_special_tokens??!1;this.tokenizer.padding_side="left";const{input_ids:i,attention_mask:o}=this.tokenizer(t,{add_special_tokens:a,padding:!0,truncation:!0}),n=await this.model.generate(i,e,null,{inputs_attention_mask:o}),c=this.tokenizer.batch_decode(n,{skip_special_tokens:!0}),u=Array.from({length:t.length},p=>[]);for(let p=0;p<c.length;++p){const m=Math.floor(p/n.length*t.length);u[m].push({generated_text:c[p]})}return!s&&u.length===1?u[0]:u}}class It extends y{constructor(t){super(t),this.label2id=Object.fromEntries(Object.entries(this.model.config.label2id).map(([e,s])=>[e.toLowerCase(),s])),this.entailment_id=this.label2id.entailment,this.entailment_id===void 0&&(console.warn("Could not find 'entailment' in label2id mapping. Using 2 as entailment_id."),this.entailment_id=2),this.contradiction_id=this.label2id.contradiction??this.label2id.not_entailment,this.contradiction_id===void 0&&(console.warn("Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id."),this.contradiction_id=0)}async _call(t,e,{hypothesis_template:s="This example is {}.",multi_label:a=!1}={}){const i=Array.isArray(t);i||(t=[t]),Array.isArray(e)||(e=[e]);const o=e.map(u=>s.replace("{}",u)),n=a||e.length===1,c=[];for(const u of t){const p=[];for(const r of o){const f=this.tokenizer(u,{text_pair:r,padding:!0,truncation:!0}),h=await this.model(f);n?p.push([h.logits.data[this.contradiction_id],h.logits.data[this.entailment_id]]):p.push(h.logits.data[this.entailment_id])}const d=(n?p.map(r=>M(r)[1]):M(p)).map((r,f)=>[r,f]).sort((r,f)=>f[0]-r[0]);c.push({sequence:u,labels:d.map(r=>e[r[1]]),scores:d.map(r=>r[0])})}return i?c:c[0]}}class Tt extends y{constructor(t){super(t)}async _call(t,{pooling:e="none",normalize:s=!1}={}){const a=this.tokenizer(t,{padding:!0,truncation:!0}),i=await this.model(a);let o=i.last_hidden_state??i.logits;if(e!=="none")if(e==="mean")o=ht(o,a.attention_mask);else if(e==="cls")o=o.slice(null,0);else throw Error(`Pooling method '${e}' not supported.`);return s&&(o=o.normalize(2,-1)),o}}class Pt extends y{constructor(t){super(t)}async _call(t,{pool:e=null}={}){const s=await I(t),{pixel_values:a}=await this.processor(s),i=await this.model({pixel_values:a});let o;if(e){if(!("pooler_output"in i))throw Error("No pooled output was returned. Make sure the model has a 'pooler' layer when using the 'pool' option.");o=i.pooler_output}else o=i.last_hidden_state??i.logits??i.image_embeds;return o}}class Ft extends y{constructor(t){super(t)}async _call(t,{topk:e=null}={}){const s=!Array.isArray(t),a=this.processor.feature_extractor.config.sampling_rate,i=await S(t,a),o=this.model.config.id2label,n=[];for(const c of i){const u=await this.processor(c),m=(await this.model(u)).logits[0],r=R(M(m.data),e).map(f=>({label:o[f[0]],score:f[1]}));e===1?n.push(...r):n.push(r)}return!s||e===1?n:n[0]}}class St extends y{constructor(t){super(t)}async _call(t,e,{hypothesis_template:s="This is a sound of {}."}={}){const a=!Array.isArray(t);a&&(t=[t]);const i=e.map(p=>s.replace("{}",p)),o=this.tokenizer(i,{padding:!0,truncation:!0}),n=this.processor.feature_extractor.config.sampling_rate,c=await S(t,n),u=[];for(const p of c){const m=await this.processor(p),d=await this.model({...o,...m}),r=M(d.logits_per_audio.data);u.push([...r].map((f,h)=>({score:f,label:e[h]})))}return a?u[0]:u}}class Rt extends y{constructor(t){super(t)}async _call(t,e={}){switch(this.model.config.model_type){case"whisper":return this._call_whisper(t,e);case"wav2vec2":case"wav2vec2-bert":case"unispeech":case"unispeech-sat":case"hubert":return this._call_wav2vec2(t,e);default:throw new Error(`AutomaticSpeechRecognitionPipeline does not support model type '${this.model.config.model_type}'.`)}}async _call_wav2vec2(t,e={}){e.language&&console.warn('`language` parameter is not yet supported for `wav2vec2` models, defaulting to "English".'),e.task&&console.warn('`task` parameter is not yet supported for `wav2vec2` models, defaulting to "transcribe".');const s=!Array.isArray(t);s&&(t=[t]);const a=this.processor.feature_extractor.config.sampling_rate,i=await S(t,a),o=[];for(const n of i){const c=await this.processor(n),p=(await this.model(c)).logits[0],m=[];for(const r of p)m.push(C(r.data)[1]);const d=this.tokenizer.decode(m);o.push({text:d})}return s?o[0]:o}async _call_whisper(t,e={}){const s=e.return_timestamps??!1,a=e.chunk_length_s??0,i=e.chunk_callback??null,o=e.force_full_sequences??!1;let n=e.stride_length_s??null;s==="word"&&(e.return_token_timestamps=!0);const c=U(e,"language",null),u=U(e,"task",null);if(c||u||s){if(e.forced_decoder_ids)throw new Error("Cannot specify `language`/`task`/`return_timestamps` and `forced_decoder_ids` at the same time.");const g=this.tokenizer.get_decoder_prompt_ids({language:c,task:u,no_timestamps:!s});g.length>0&&(e.forced_decoder_ids=g)}const p=!Array.isArray(t);p&&(t=[t]);const m=this.processor.feature_extractor.config.chunk_length/this.model.config.max_source_positions,d=this.processor.feature_extractor.config.hop_length,r=this.processor.feature_extractor.config.sampling_rate,f=await S(t,r),h=[];for(const g of f){let _=[];if(a>0){if(n===null)n=a/6;else if(a<=n)throw Error("`chunk_length_s` must be larger than `stride_length_s`.");const k=r*a,z=r*n,A=k-2*z;let T=0;for(;T<g.length;){const L=g.subarray(T,T+k),Q=await this.processor(L),Z=T===0,j=T+A>=g.length;_.push({stride:[L.length,Z?0:z,j?0:z],input_features:Q.input_features,is_last:j}),T+=A}}else _=[{stride:[g.length,0,0],input_features:(await this.processor(g)).input_features,is_last:!0}];for(const k of _){e.num_frames=Math.floor(k.stride[0]/d);const z=await this.model.generate(k.input_features,e);s==="word"?(k.tokens=z.sequences[0],k.token_timestamps=z.token_timestamps.tolist()[0].map(A=>_t(A,2))):k.tokens=z[0],k.stride=k.stride.map(A=>A/r),i!==null&&i(k)}const[w,v]=this.tokenizer._decode_asr(_,{time_precision:m,return_timestamps:s,force_full_sequences:o});h.push({text:w,...v})}return p?h[0]:h}}class Et extends y{constructor(t){super(t)}async _call(t,e={}){const s=Array.isArray(t),a=await I(t),{pixel_values:i}=await this.processor(a),o=[];for(const n of i){n.dims=[1,...n.dims];const c=await this.model.generate(n,e),u=this.tokenizer.batch_decode(c,{skip_special_tokens:!0}).map(p=>({generated_text:p.trim()}));o.push(u)}return s?o:o[0]}}class qt extends y{constructor(t){super(t)}async _call(t,{topk:e=1}={}){const s=Array.isArray(t),a=await I(t),{pixel_values:i}=await this.processor(a),o=await this.model({pixel_values:i}),n=this.model.config.id2label,c=[];for(const u of o.logits){const m=R(M(u.data),e).map(d=>({label:n[d[0]],score:d[1]}));e===1?c.push(...m):c.push(m)}return s||e===1?c:c[0]}}class Ct extends y{constructor(t){super(t),this.subtasks_mapping={panoptic:"post_process_panoptic_segmentation",instance:"post_process_instance_segmentation",semantic:"post_process_semantic_segmentation"}}async _call(t,{threshold:e=.5,mask_threshold:s=.5,overlap_mask_area_threshold:a=.8,label_ids_to_fuse:i=null,target_sizes:o=null,subtask:n=null}={}){if(Array.isArray(t)&&t.length!==1)throw Error("Image segmentation pipeline currently only supports a batch size of 1.");const u=await I(t),p=u.map(_=>[_.height,_.width]),{pixel_values:m,pixel_mask:d}=await this.processor(u),r=await this.model({pixel_values:m,pixel_mask:d});let f=null;if(n!==null)f=this.subtasks_mapping[n];else for(let[_,w]of Object.entries(this.subtasks_mapping))if(w in this.processor.feature_extractor){f=this.processor.feature_extractor[w].bind(this.processor.feature_extractor),n=_;break}const h=this.model.config.id2label,g=[];if(n==="panoptic"||n==="instance"){const _=f(r,e,s,a,i,o??p)[0],w=_.segmentation;for(const v of _.segments_info){const k=new Uint8ClampedArray(w.data.length);for(let A=0;A<w.data.length;++A)w.data[A]===v.id&&(k[A]=255);const z=new F(k,w.dims[1],w.dims[0],1);g.push({score:v.score,label:h[v.label_id],mask:z})}}else if(n==="semantic"){const{segmentation:_,labels:w}=f(r,o??p)[0];for(const v of w){const k=new Uint8ClampedArray(_.data.length);for(let A=0;A<_.data.length;++A)_.data[A]===v&&(k[A]=255);const z=new F(k,_.dims[1],_.dims[0],1);g.push({score:null,label:h[v],mask:z})}}else throw Error(`Subtask ${n} not supported.`);return g}}class Xt extends y{constructor(t){super(t)}async _call(t,e,{hypothesis_template:s="This is a photo of {}"}={}){const a=Array.isArray(t),i=await I(t),o=e.map(d=>s.replace("{}",d)),n=this.tokenizer(o,{padding:this.model.config.model_type==="siglip"?"max_length":!0,truncation:!0}),{pixel_values:c}=await this.processor(i),u=await this.model({...n,pixel_values:c}),p=this.model.config.model_type==="siglip"?d=>d.sigmoid().data:d=>M(d.data),m=[];for(const d of u.logits_per_image){const f=[...p(d)].map((h,g)=>({score:h,label:e[g]}));f.sort((h,g)=>g.score-h.score),m.push(f)}return a?m:m[0]}}class Ot extends y{constructor(t){super(t)}async _call(t,{threshold:e=.9,percentage:s=!1}={}){const a=Array.isArray(t);if(a&&t.length!==1)throw Error("Object detection pipeline currently only supports a batch size of 1.");const i=await I(t),o=s?null:i.map(r=>[r.height,r.width]),{pixel_values:n,pixel_mask:c}=await this.processor(i),u=await this.model({pixel_values:n,pixel_mask:c}),p=this.processor.feature_extractor.post_process_object_detection(u,e,o),m=this.model.config.id2label,d=p.map(r=>r.boxes.map((f,h)=>({score:r.scores[h],label:m[r.classes[h]],box:N(f,!s)})));return a?d:d[0]}}class Lt extends y{constructor(t){super(t)}async _call(t,e,{threshold:s=.1,topk:a=null,percentage:i=!1}={}){const o=Array.isArray(t),n=await I(t),c=this.tokenizer(e,{padding:!0,truncation:!0}),u=await this.processor(n),p=[];for(let m=0;m<n.length;++m){const d=n[m],r=i?null:[[d.height,d.width]],f=u.pixel_values[m].unsqueeze_(0),h=await this.model({...c,pixel_values:f}),g=this.processor.feature_extractor.post_process_object_detection(h,s,r,!0)[0];let _=g.boxes.map((w,v)=>({score:g.scores[v],label:e[g.classes[v]],box:N(w,!i)})).sort((w,v)=>v.score-w.score);a!==null&&(_=_.slice(0,a)),p.push(_)}return o?p:p[0]}}class jt extends y{constructor(t){super(t)}async _call(t,e,s={}){const a=(await I(t))[0],{pixel_values:i}=await this.processor(a),o=`<s_docvqa><s_question>${e}</s_question><s_answer>`,n=this.tokenizer(o,{add_special_tokens:!1,padding:!0,truncation:!0}).input_ids,c=await this.model.generate(i,{...s,decoder_input_ids:n,max_length:this.model.config.decoder.max_position_embeddings}),p=this.tokenizer.batch_decode(c)[0].match(/<s_answer>(.*?)<\/s_answer>/);let m=null;return p&&p.length>=2&&(m=p[1].trim()),[{answer:m}]}}class Dt extends y{DEFAULT_VOCODER_ID="Xenova/speecht5_hifigan";constructor(t){super(t),this.vocoder=t.vocoder??null}async _call(t,{speaker_embeddings:e=null}={}){return this.processor?this._call_text_to_spectrogram(t,{speaker_embeddings:e}):this._call_text_to_waveform(t)}async _call_text_to_waveform(t){const e=this.tokenizer(t,{padding:!0,truncation:!0}),{waveform:s}=await this.model(e),a=this.model.config.sampling_rate;return{audio:s.data,sampling_rate:a}}async _call_text_to_spectrogram(t,{speaker_embeddings:e}){if(this.vocoder||(console.log("No vocoder specified, using default HifiGan vocoder."),this.vocoder=await P.from_pretrained(this.DEFAULT_VOCODER_ID,{dtype:"fp32"})),(typeof e=="string"||e instanceof URL)&&(e=new Float32Array(await(await fetch(e)).arrayBuffer())),e instanceof Float32Array)e=new B("float32",e,[1,e.length]);else if(!(e instanceof B))throw new Error("Speaker embeddings must be a `Tensor`, `Float32Array`, `string`, or `URL`.");const{input_ids:s}=this.tokenizer(t,{padding:!0,truncation:!0}),{waveform:a}=await this.model.generate_speech(s,e,{vocoder:this.vocoder}),i=this.processor.feature_extractor.config.sampling_rate;return{audio:a.data,sampling_rate:i}}}class Ut extends y{constructor(t){super(t)}async _call(t){const e=await I(t),s=await this.processor(e),a=await this.model(s),i=[];for(const o of a.reconstruction){const n=o.squeeze().clamp_(0,1).mul_(255).round_().to("uint8");i.push(F.fromTensor(n))}return i.length>1?i:i[0]}}class Bt extends y{constructor(t){super(t)}async _call(t){const e=await I(t),s=await this.processor(e),{predicted_depth:a}=await this.model(s),i=[];for(let o=0;o<e.length;++o){const n=gt(a[o],e[o].size.reverse(),"bilinear",!1),c=n.mul_(255/C(n.data)[0]).to("uint8");i.push({predicted_depth:a[o],depth:F.fromTensor(c)})}return i.length>1?i:i[0]}}const $=Object.freeze({"text-classification":{tokenizer:x,pipeline:xt,model:D,default:{model:"Xenova/distilbert-base-uncased-finetuned-sst-2-english"},type:"text"},"token-classification":{tokenizer:x,pipeline:At,model:K,default:{model:"Xenova/bert-base-multilingual-cased-ner-hrl"},type:"text"},"question-answering":{tokenizer:x,pipeline:bt,model:V,default:{model:"Xenova/distilbert-base-cased-distilled-squad"},type:"text"},"fill-mask":{tokenizer:x,pipeline:vt,model:W,default:{model:"Xenova/bert-base-uncased"},type:"text"},summarization:{tokenizer:x,pipeline:zt,model:E,default:{model:"Xenova/distilbart-cnn-6-6"},type:"text"},translation:{tokenizer:x,pipeline:G,model:E,default:{model:"Xenova/t5-small"},type:"text"},"text2text-generation":{tokenizer:x,pipeline:X,model:E,default:{model:"Xenova/flan-t5-small"},type:"text"},"text-generation":{tokenizer:x,pipeline:Mt,model:J,default:{model:"Xenova/gpt2"},type:"text"},"zero-shot-classification":{tokenizer:x,pipeline:It,model:D,default:{model:"Xenova/distilbert-base-uncased-mnli"},type:"text"},"audio-classification":{pipeline:Ft,model:Y,processor:b,default:{model:"Xenova/wav2vec2-base-superb-ks"},type:"audio"},"zero-shot-audio-classification":{tokenizer:x,pipeline:St,model:P,processor:b,default:{model:"Xenova/clap-htsat-unfused"},type:"multimodal"},"automatic-speech-recognition":{tokenizer:x,pipeline:Rt,model:[tt,et],processor:b,default:{model:"Xenova/whisper-tiny.en"},type:"multimodal"},"text-to-audio":{tokenizer:x,pipeline:Dt,model:[st,ot],processor:[b,null],default:{model:"Xenova/speecht5_tts"},type:"text"},"image-to-text":{tokenizer:x,pipeline:Et,model:nt,processor:b,default:{model:"Xenova/vit-gpt2-image-captioning"},type:"multimodal"},"image-classification":{pipeline:qt,model:it,processor:b,default:{model:"Xenova/vit-base-patch16-224"},type:"multimodal"},"image-segmentation":{pipeline:Ct,model:[at,rt],processor:b,default:{model:"Xenova/detr-resnet-50-panoptic"},type:"multimodal"},"zero-shot-image-classification":{tokenizer:x,pipeline:Xt,model:P,processor:b,default:{model:"Xenova/clip-vit-base-patch32"},type:"multimodal"},"object-detection":{pipeline:Ot,model:lt,processor:b,default:{model:"Xenova/detr-resnet-50"},type:"multimodal"},"zero-shot-object-detection":{tokenizer:x,pipeline:Lt,model:ct,processor:b,default:{model:"Xenova/owlvit-base-patch32"},type:"multimodal"},"document-question-answering":{tokenizer:x,pipeline:jt,model:pt,processor:b,default:{model:"Xenova/donut-base-finetuned-docvqa"},type:"multimodal"},"image-to-image":{pipeline:Ut,model:ut,processor:b,default:{model:"Xenova/swin2SR-classical-sr-x2-64"},type:"image"},"depth-estimation":{pipeline:Bt,model:dt,processor:b,default:{model:"Xenova/dpt-large"},type:"image"},"feature-extraction":{tokenizer:x,pipeline:Tt,model:P,default:{model:"Xenova/all-MiniLM-L6-v2"},type:"text"},"image-feature-extraction":{processor:b,pipeline:Pt,model:[mt,P],default:{model:"Xenova/vit-base-patch16-224-in21k"},type:"image"}}),$t=Object.freeze({"sentiment-analysis":"text-classification",ner:"token-classification",asr:"automatic-speech-recognition","text-to-speech":"text-to-audio",embeddings:"feature-extraction"});async function Nt(l,t=null,{progress_callback:e=null,config:s=null,cache_dir:a=null,local_files_only:i=!1,revision:o="main",device:n=null,dtype:c=null,session_options:u={}}={}){l=$t[l]??l;const p=$[l.split("_",1)[0]];if(!p)throw Error(`Unsupported pipeline: ${l}. Must be one of [${Object.keys($)}]`);t||(t=p.default.model,console.log(`No model specified. Using default model: "${t}".`));const m={progress_callback:e,config:s,cache_dir:a,local_files_only:i,revision:o,device:n,dtype:c,session_options:u},d=new Map([["tokenizer",p.tokenizer],["model",p.model],["processor",p.processor]]),r=await Gt(d,t,m);r.task=l,H(e,{status:"ready",task:l,model:t});const f=p.pipeline;return new f(r)}async function Gt(l,t,e){const s=Object.create(null),a=[];for(let[i,o]of l.entries()){if(!o)continue;let n;Array.isArray(o)?n=new Promise(async(c,u)=>{let p;for(let m of o){if(m===null){c(null);return}try{c(await m.from_pretrained(t,e));return}catch(d){if(d.message?.includes("Unsupported model type"))p=d;else{u(d);return}}}u(p)}):n=o.from_pretrained(t,e),s[i]=n,a.push(n)}await Promise.all(a);for(let[i,o]of Object.entries(s))s[i]=await o;return s}q.allowLocalModels=!1,q.allowRemoteModels=!0;const Qt={"question-answering":Vt,summarization:Wt,"image-to-text":Jt};self.addEventListener("message",async l=>{const{baseURI:t}=l.data;t&&(q.localModelPath=new URL(t).origin+kt);const e=l.data;let s=Qt[e.task];if(!s)return;let a=await s(e);self.postMessage({task:e.task,type:"result",data:a})});class O{static task=null;static model=null;static instance=null;constructor(t,e){this.tokenizer=t,this.model=e}static getInstance(t=null){if(this.task===null||this.model===null)throw Error("Must set task and model");return this.instance===null&&(this.instance=Nt(this.task,this.model,{progress_callback:t})),this.instance}}class Zt extends O{static task="question-answering";static model="Xenova/distilbert-base-cased-distilled-squad"}class Ht extends O{static task="summarization";static model="Xenova/distilbart-cnn-6-6"}class Kt extends O{static task="image-to-text";static model="Xenova/vit-gpt2-image-captioning"}async function Vt(l){let e=await(await Zt.getInstance(s=>{self.postMessage({type:"download",task:"question-answering",data:s})}))(l.question,l.context);return self.postMessage({type:"complete",target:l.elementIdToUpdate,data:e.answer}),e}async function Wt(l){let t=await Ht.getInstance(e=>{self.postMessage({type:"download",task:"summarization",data:e})});return await t(l.text,{...l.generation,callback_function:function(e){const s=t.tokenizer.decode(e[0].output_token_ids,{skip_special_tokens:!0});self.postMessage({type:"update",target:l.elementIdToUpdate,data:s.trim()})}})}async function Jt(l){let t=await Kt.getInstance(e=>{self.postMessage({type:"download",task:"image-to-text",data:e})});return await t(l.image,{...l.generation,callback_function:function(e){const s=t.tokenizer.decode(e[0].output_token_ids,{skip_special_tokens:!0});self.postMessage({type:"update",target:l.elementIdToUpdate,data:s.trim()})}})}
